{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as NeuralNet\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 4\n",
    "learning_rate = 0.001\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), \n",
    "                              transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "training_dataset = torchvision.datasets.CIFAR10('Data', train=True, download=True,\n",
    "                                                 transform=transform)\n",
    "testing_dataset = torchvision.datasets.CIFAR10('Data', train=False, transform=transform)\n",
    "\n",
    "training_loader = torch.utils.data.DataLoader(dataset=training_dataset,\n",
    "                                                batch_size=batch_size, shuffle=True)\n",
    "testing_loader = torch.utils.data.DataLoader(dataset=testing_dataset,\n",
    "                                                batch_size=batch_size, shuffle=False)\n",
    "                                    \n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "            'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(NeuralNet.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet,self).__init__()\n",
    "        self.conv1 = NeuralNet.Conv2d(in_channels=3, out_channels=6, kernel_size=5)\n",
    "\n",
    "        self.pool= NeuralNet.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.Conv2 = NeuralNet.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        \n",
    "        self.dense1 = NeuralNet.Linear(in_features=16*5*5, out_features=120)\n",
    "\n",
    "        self.dense2 = NeuralNet.Linear(in_features=120, out_features=84)\n",
    "\n",
    "        self.dense3 = NeuralNet.Linear(in_features=84, out_features=10) \n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.Conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 16*5*5)\n",
    "        x =  F.relu(self.dense1(x))\n",
    "        x =  F.relu(self.dense2(x))\n",
    "        x =  self.dense3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= ConvNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and optimiser\n",
    "\n",
    "criterion = NeuralNet.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 / 10, step 2000 / 12500, loss = 2.3168\n",
      "epoch 1 / 10, step 4000 / 12500, loss = 2.3104\n",
      "epoch 1 / 10, step 6000 / 12500, loss = 2.3142\n",
      "epoch 1 / 10, step 8000 / 12500, loss = 2.2715\n",
      "epoch 1 / 10, step 10000 / 12500, loss = 2.3898\n",
      "epoch 1 / 10, step 12000 / 12500, loss = 1.8506\n",
      "epoch 2 / 10, step 2000 / 12500, loss = 2.0526\n",
      "epoch 2 / 10, step 4000 / 12500, loss = 2.0624\n",
      "epoch 2 / 10, step 6000 / 12500, loss = 2.2503\n",
      "epoch 2 / 10, step 8000 / 12500, loss = 2.9184\n",
      "epoch 2 / 10, step 10000 / 12500, loss = 1.5642\n",
      "epoch 2 / 10, step 12000 / 12500, loss = 1.9651\n",
      "epoch 3 / 10, step 2000 / 12500, loss = 2.0121\n",
      "epoch 3 / 10, step 4000 / 12500, loss = 1.6561\n",
      "epoch 3 / 10, step 6000 / 12500, loss = 1.2073\n",
      "epoch 3 / 10, step 8000 / 12500, loss = 1.6669\n",
      "epoch 3 / 10, step 10000 / 12500, loss = 1.5073\n",
      "epoch 3 / 10, step 12000 / 12500, loss = 1.0615\n",
      "epoch 4 / 10, step 2000 / 12500, loss = 2.0125\n",
      "epoch 4 / 10, step 4000 / 12500, loss = 1.0413\n",
      "epoch 4 / 10, step 6000 / 12500, loss = 1.2179\n",
      "epoch 4 / 10, step 8000 / 12500, loss = 0.8081\n",
      "epoch 4 / 10, step 10000 / 12500, loss = 1.1715\n",
      "epoch 4 / 10, step 12000 / 12500, loss = 1.1685\n",
      "epoch 5 / 10, step 2000 / 12500, loss = 0.7686\n",
      "epoch 5 / 10, step 4000 / 12500, loss = 2.0505\n",
      "epoch 5 / 10, step 6000 / 12500, loss = 1.3246\n",
      "epoch 5 / 10, step 8000 / 12500, loss = 1.6910\n",
      "epoch 5 / 10, step 10000 / 12500, loss = 1.9933\n",
      "epoch 5 / 10, step 12000 / 12500, loss = 1.7218\n",
      "epoch 6 / 10, step 2000 / 12500, loss = 2.3675\n",
      "epoch 6 / 10, step 4000 / 12500, loss = 1.1651\n",
      "epoch 6 / 10, step 6000 / 12500, loss = 0.7585\n",
      "epoch 6 / 10, step 8000 / 12500, loss = 1.7600\n",
      "epoch 6 / 10, step 10000 / 12500, loss = 1.3628\n",
      "epoch 6 / 10, step 12000 / 12500, loss = 1.1898\n",
      "epoch 7 / 10, step 2000 / 12500, loss = 1.6330\n",
      "epoch 7 / 10, step 4000 / 12500, loss = 1.0218\n",
      "epoch 7 / 10, step 6000 / 12500, loss = 1.9430\n",
      "epoch 7 / 10, step 8000 / 12500, loss = 1.0095\n",
      "epoch 7 / 10, step 10000 / 12500, loss = 1.7653\n",
      "epoch 7 / 10, step 12000 / 12500, loss = 1.2796\n",
      "epoch 8 / 10, step 2000 / 12500, loss = 2.0329\n",
      "epoch 8 / 10, step 4000 / 12500, loss = 1.1833\n",
      "epoch 8 / 10, step 6000 / 12500, loss = 2.0340\n",
      "epoch 8 / 10, step 8000 / 12500, loss = 1.8471\n",
      "epoch 8 / 10, step 10000 / 12500, loss = 1.3835\n",
      "epoch 8 / 10, step 12000 / 12500, loss = 1.1679\n",
      "epoch 9 / 10, step 2000 / 12500, loss = 1.3574\n",
      "epoch 9 / 10, step 4000 / 12500, loss = 1.2744\n",
      "epoch 9 / 10, step 6000 / 12500, loss = 0.7282\n",
      "epoch 9 / 10, step 8000 / 12500, loss = 0.9548\n",
      "epoch 9 / 10, step 10000 / 12500, loss = 3.5494\n",
      "epoch 9 / 10, step 12000 / 12500, loss = 0.8346\n",
      "epoch 10 / 10, step 2000 / 12500, loss = 1.1240\n",
      "epoch 10 / 10, step 4000 / 12500, loss = 1.5054\n",
      "epoch 10 / 10, step 6000 / 12500, loss = 0.9861\n",
      "epoch 10 / 10, step 8000 / 12500, loss = 1.1888\n",
      "epoch 10 / 10, step 10000 / 12500, loss = 0.3262\n",
      "epoch 10 / 10, step 12000 / 12500, loss = 0.9774\n",
      "training finished\n"
     ]
    }
   ],
   "source": [
    "n_total_steps = len(training_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i,(images, labels) in enumerate(training_loader):\n",
    "\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        ouputs = model(images)\n",
    "\n",
    "        loss = criterion(ouputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        if (i+1) % 2000 == 0:\n",
    "            print(f'epoch {epoch + 1} / {num_epochs}, step {i + 1} / {n_total_steps}, loss = {loss.item():.4f}')\n",
    "\n",
    "print('training finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the network: 0.03 %\n",
      "Accuracy of plane: 52.0 %\n",
      "Accuracy of car: 55.2 %\n",
      "Accuracy of bird: 38.4 %\n",
      "Accuracy of cat: 25.5 %\n",
      "Accuracy of deer: 39.0 %\n",
      "Accuracy of dog: 61.6 %\n",
      "Accuracy of frog: 75.2 %\n",
      "Accuracy of horse: 60.5 %\n",
      "Accuracy of ship: 71.8 %\n",
      "Accuracy of truck: 69.9 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(10)]\n",
    "    n_class_samples = [0 for i in range(10)]\n",
    "    for images, labels in testing_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        ouputs = model(images)\n",
    "\n",
    "        _, Prediction = torch.max(ouputs, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct = (Prediction == labels).sum().item()\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            label = labels[i]\n",
    "            pred = Prediction[i]\n",
    "            if(label == pred):\n",
    "                n_class_correct[label] += 1\n",
    "            n_class_samples[label] += 1\n",
    "    \n",
    "    \n",
    "    acc = 100 * n_correct / n_samples\n",
    "\n",
    "    print(f'accuracy of the network: {acc} %')\n",
    "\n",
    "    for i in range(10):\n",
    "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "        print(f'Accuracy of {classes[i]}: {acc} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2ee4e78e375ce87483e1695e33615481c2908b7ea7fe840a873f99ff05403af4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
